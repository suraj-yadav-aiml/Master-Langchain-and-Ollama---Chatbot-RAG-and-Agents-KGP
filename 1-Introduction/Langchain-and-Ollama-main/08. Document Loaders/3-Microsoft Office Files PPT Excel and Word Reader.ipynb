{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcement-on-ML\n",
    "<a href='http://www.kgptalkie.com' target=\"_blank\"> <img src='https://github.com/laxmimerit/Important-Announcement-on-ML/raw/master/kgptalkie_strips.png'/></a>\n",
    "\n",
    "# ML Resources\n",
    "|  ML Course | Description |\n",
    "|:---|:---|\n",
    "| [**Deploy LLM App with Ollama and Langchain in Production**](https://www.udemy.com/course/ollama-and-langchain/?referralCode=7F4C0C7B8CF223BA9327) | Master Langchain v0.3, Private Chatbot, Deploy LLM App.  Ollama, LLAMA, LLAMA 3.2, FAISS, RAG, Deploy RAG, Gen AI, LLM|\n",
    "| [**Fine Tuning LLM with HuggingFace Transformers for NLP**](https://www.udemy.com/course/fine-tuning-llm-with-hugging-face-transformers/?referralCode=6DEB3BE17C2644422D8E) | Learn how to fine tune LLM with custom dataset. You will learn basics of transformers then fine tune LLM|\n",
    "| [**Data Visualization in Python Masterclassâ„¢: Beginners to Pro**](https://bit.ly/udemy95off_kgptalkie) |  Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Python for Machine Learning: A Step-by-Step Guide**](https://bit.ly/ml-ds-project) | Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Deep Learning for Beginners with Python**](https://bit.ly/dl-with-python) | Neural Networks, TensorFlow, ANN, CNN, RNN, LSTM, Transfer Learning and Much More. |\n",
    "| [**Python for Linear Regression in Machine Learning**](https://bit.ly/regression-python) | Learn to build Linear Regression models using Python and its libraries like Scikit-Learn. |\n",
    "| [**Introduction to Spacy 3 for Natural Language Processing**](https://bit.ly/spacy-intro) | Learn to build Natural Language Processing models using Python and its libraries like Spacy. |\n",
    "| [**Advanced Machine Learning and Deep Learning Projects**](https://bit.ly/kgptalkie_ml_projects) | Learn to build Advanced Machine Learning and Deep Learning models using Python and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Natural Language Processing in Python for Beginners**](https://bit.ly/intro_nlp) | Learn to build Natural Language Processing Projects using Spacy, NLTK, and Gensim, and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Deployment of Machine Learning Models in Production in Python**](https://bit.ly/bert_nlp) |  Learn to deploy Machine Learning and Deep Learning models using Python and its libraries like Flask, Streamlit, and NGINX. |\n",
    "| [**R 4.0 Programming for Data Science - Beginners to Pro**](https://bit.ly/r4-ml) | Learn to build Machine Learning and Deep Learning models using R and its libraries like caret, tidyverse, and keras. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsoft Office Files PPT Excel and Word Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:**\n",
    "Unstructured Data Reader Setup\n",
    "\n",
    "https://python.langchain.com/docs/integrations/providers/unstructured/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 1: Key Notes and Script Generation for PPT Presentor (Speaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "OSError: No such file or directory: 'C:\\Users\\laxmi\\AppData\\Roaming\\nltk_data\\tokenizers\\punkt\\PY3_tab'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Handling:\n",
    "C:\\Users\\laxmi\\AppData\\Roaming\\nltk_data\\tokenizers\\punkt --> PY3 to PY3_tab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\laxmi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unstructured openpyxl python-magic python-pptx\n",
    "# pip install \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "\n",
    "loader = UnstructuredPowerPointLoader(\"data/ml_course.pptx\", mode=\"elements\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning Model Deployment'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = docs[0]\n",
    "doc.metadata\n",
    "doc.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_data = {}\n",
    "for doc in docs:\n",
    "    page = doc.metadata[\"page_number\"]\n",
    "    ppt_data[page] = ppt_data.get(page, \"\")  + \"\\n\\n\" + doc.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '\\n\\nMachine Learning Model Deployment\\n\\nIntroduction to ML Pipeline\\n\\nhttps://bit.ly/bert_nlp\\n\\n',\n",
       " 2: '\\n\\nWhat is Machine Learning Pipeline?\\n\\n',\n",
       " 3: '\\n\\nType of ML Deployment\\n\\nBatch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.\\n\\nStream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\\n\\nRealtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.\\n\\nEdge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.\\n\\n',\n",
       " 4: '\\n\\nInfrastructure and Integration\\n\\nHardware and Software: Setting up the right environment for model deployment.\\n\\nIntegration: Seamlessly integrating the model with existing systems and applications.\\n\\n',\n",
       " 5: '\\n\\nBenefits of Deploying ML Models\\n\\nFocus on new models, not maintaining existing models || Prevention of bugs || Creation of records for debugging and reproducing results || Standardization || Allows models to handle real-time data and large user bases.\\n\\n',\n",
       " 6: '\\n\\nChallenges in ML Deployment\\n\\nData Management: Making sure the model gets the right kind of data.\\n\\nModel Scalability and Performance: Ensuring that their model can effectively scale as it keeps adding more complex information.\\n\\nIntegration with Existing Systems: Fitting the model into current computers and software.\\n\\nMonitoring and Maintenance: Watching and fixing the model over time.\\n\\nSecurity and Privacy: Protecting data and keeping it private.\\n\\nResource Management: Using computer resources like memory and power wisely.\\n\\nVersioning and Model Management: Keeping track of different versions of the model.\\n\\nRegulatory Compliance: Making sure the model follows the laws, rules, and regulations.\\n\\nUser Acceptance and Trust: Getting people to trust and accept the model.\\n\\nExplainability and Transparency: Being able to explain how the model works.\\n\\nCost Management: Managing how much it costs to use the model.\\n\\nAs per research, only 13% of ML models ever make it to production. This is a huge gap, considering the possibilities that AI model deployment can bring to the organization.\\n\\n',\n",
       " 7: '\\n\\nData and Model Management\\n\\nData Pipelines: Building and maintaining data pipelines for continuous data flow.\\n\\nModel Versioning: Tracking and managing different versions of models.\\n\\n',\n",
       " 8: '\\n\\nA/B Testing\\n\\nObjective Comparison: A/B testing allows for an objective comparison of two model versions to determine which performs better based on specific metrics.\\n\\nReal-World Application: It is widely used to optimize user experiences, such as testing different recommendation systems or ad strategies to enhance engagement or conversion rates.\\n\\nStatistical Significance: The technique ensures that performance differences are statistically significant and not due to random chance by using control and treatment groups along with statistical tests.\\n\\n',\n",
       " 9: '\\n\\nSecurity, Compliance and Bias\\n\\nSecurity: Ensuring the security of machine learning models involves protecting sensitive data from unauthorized access and breaches through robust encryption, secure APIs, and access controls\\n\\nCompliance: Adhering to industry regulations and standards, such as GDPR or HIPAA, is critical to ensure the legal and ethical use of data in machine learning deployments. This involves data anonymization, user consent, and regular compliance audits.\\n\\nBias Detection: Identifying and mitigating bias in ML models is crucial to prevent unfair and discriminatory outcomes. This involves using diverse training datasets, applying fairness-aware algorithms, and conducting bias impact assessments\\n\\nContinuous Monitoring: Regular monitoring and updating of deployed models are essential to maintain security, compliance, and fairness. This involves real-time performance tracking, automated alerts for anomalies, and periodic model retraining.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "for page, content in ppt_data.items():\n",
    "    context += f\"### Slide {page}:\\n\\n{content.strip()}\\n\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM Code\n",
    "from scripts import llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question =\"\"\"\n",
    "For each PowerPoint slide provided above, write a 2-minute script that effectively conveys the key points.\n",
    "Ensure a smooth flow between slides, maintaining a clear and engaging narrative.\n",
    "\"\"\"\n",
    "\n",
    "response = llm.ask_llm(context, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response)\n",
    "with open(\"data/ppt_script.md\", \"w\") as f:\n",
    "    f.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 2: Excel Data Analysis with LLM \n",
    "**Note:** Currently LLMs are not good in Math and Data Analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import  UnstructuredExcelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Name Last Name City Gender Brandon James Miami M Sean Hawkins Denver M Judy Day Los Angeles F Ashley Ruiz San Francisco F Stephanie Gomez Portland F'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = UnstructuredExcelLoader(\"data/sample.xlsx\",  mode=\"elements\")\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs)\n",
    "\n",
    "doc = docs[0]\n",
    "doc.metadata\n",
    "\n",
    "doc.page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = doc.metadata['text_as_html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table><tr><td>First Name</td><td>Last Name</td><td>City</td><td>Gender</td></tr><tr><td>Brandon</td><td>James</td><td>Miami</td><td>M</td></tr><tr><td>Sean</td><td>Hawkins</td><td>Denver</td><td>M</td></tr><tr><td>Judy</td><td>Day</td><td>Los Angeles</td><td>F</td></tr><tr><td>Ashley</td><td>Ruiz</td><td>San Francisco</td><td>F</td></tr><tr><td>Stephanie</td><td>Gomez</td><td>Portland</td><td>F</td></tr></table>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City | Gender |\n",
      "| --- | --- | --- | --- |\n",
      "| Brandon | James | Miami | M |\n",
      "| Sean | Hawkins | Denver | M |\n",
      "| Judy | Day | Los Angeles | F |\n",
      "| Ashley | Ruiz | San Francisco | F |\n",
      "| Stephanie | Gomez | Portland | F |\n"
     ]
    }
   ],
   "source": [
    "question = \"Return this data in Markdown format.\"\n",
    "response = llm.ask_llm(context, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City | Gender |\n",
      "|------------|-----------|------|--------|\n",
      "| Judy       | Day       | Los Angeles | F    |\n",
      "| Ashley     | Ruiz      | San Francisco | F    |\n",
      "| Stephanie  | Gomez     | Portland   | F    |\n"
     ]
    }
   ],
   "source": [
    "question = \"Return all entris in the table where Gender is 'F'. Format the response in Markdown. Do not write preambles and explanation.\"\n",
    "response = llm.ask_llm(context, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City    | Gender |\n",
      "|------------|-----------|---------|--------|\n",
      "| Brandon    | James     | Miami   | M      |\n",
      "| Sean       | Hawkins   | Denver   | M      |\n"
     ]
    }
   ],
   "source": [
    "question = \"Return all entris in the table where Gender is 'male'. Format the response in Markdown. Do not write preambles and explanation.\"\n",
    "response = llm.ask_llm(context, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 3: Personalized Job Application Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in c:\\users\\laxmi\\anaconda3\\envs\\ml\\lib\\site-packages (0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The value specified in an AutoRun registry key could not be parsed.\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import  Docx2txtLoader\n",
    "\n",
    "loader = Docx2txtLoader(\"data/job_description.docx\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Data Scientist Position at SpiceJet\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am excited to apply for the Data Scientist position at SpiceJet. As a recent graduate from IIT with a focus on Natural Language Processing and Machine Learning, I am confident that my skills and experience make me an ideal candidate for this role.\n",
      "\n",
      "With a strong foundation in mathematical and statistical expertise, I have a solid understanding of machine learning platforms and techniques, data mining, mathematics, and statistical analysis. My proficiency in programming languages such as Python and R, along with experience with Excel, Tableau, and SQL, enables me to effectively mine, clean, and interpret data.\n",
      "\n",
      "I am particularly drawn to this role because of the opportunity to apply my skills to drive business value across different parts of the business. I am excited about the prospect of collaborating with product design and engineering to develop an understanding of needs and developing statistical and machine learning models to deliver insights and automate processes.\n",
      "\n",
      "As a detail-oriented and analytical individual, I possess excellent problem-solving skills, with the ability to translate complex problems into formalized structures and troubleshoot unseen issues. My strong coding principles, including extensibility, abstraction, separation of concerns, and adherence to security requirements, ensure that my solutions are performant, integrated, and secure.\n",
      "\n",
      "I am confident that my passion for data science, combined with my academic background and industry experience, make me an excellent fit for this role. I would welcome the opportunity to discuss how my skills and experience align with the requirements of this position.\n",
      "\n",
      "Thank you for considering my application. I look forward to the opportunity to contribute to SpiceJet's success as a Data Scientist.\n",
      "\n",
      "Sincerely,\n",
      "Aaditya\n"
     ]
    }
   ],
   "source": [
    "question =\"\"\"\n",
    "My name is Aaditya, and I am a recent graduate from IIT with a focus on Natural Language Processing and Machine Learning.\n",
    "I am applying for a Data Scientist position at SpiceJet.\n",
    "Please write a concise job application email for me in short, removing any placeholders, including references to job boards or sources.\n",
    "\"\"\"\n",
    "response = llm.ask_llm(context, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
