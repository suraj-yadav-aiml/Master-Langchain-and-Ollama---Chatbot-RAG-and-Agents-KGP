{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Microsoft Office Files PPT Excel and Word Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Important Note:**\n",
    "Unstructured Data Reader Setup\n",
    "\n",
    "https://python.langchain.com/docs/integrations/providers/unstructured/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Project 1: Key Notes and Script Generation for PPT Presentor (Speaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "OSError: No such file or directory: 'C:\\Users\\laxmi\\AppData\\Roaming\\nltk_data\\tokenizers\\punkt\\PY3_tab'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Error Handling:\n",
    "C:\\Users\\laxmi\\AppData\\Roaming\\nltk_data\\tokenizers\\punkt --> PY3 to PY3_tab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unstructured openpyxl python-magic python-pptx\n",
    "# !pip install \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPowerPointLoader(file_path=\"data/ml_course.pptx\", mode='elements')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': '1378fc8ea4dd0830a3c5f93e9d31a516'}, page_content='Machine Learning Model Deployment'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 1, 'languages': ['eng'], 'parent_id': '1378fc8ea4dd0830a3c5f93e9d31a516', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': '5de650940883c293416c7f769aa0c961'}, page_content='Introduction to ML Pipeline'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 1, 'languages': ['eng'], 'parent_id': '1378fc8ea4dd0830a3c5f93e9d31a516', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': 'd5291160bba9cc08934c253ec7feee5c'}, page_content='https://bit.ly/bert_nlp'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'languages': ['eng'], 'file_directory': 'data', 'filename': 'ml_course.pptx', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'PageBreak', 'element_id': '0815278d05fe9f49c577c0ce610996e8'}, page_content=''),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 2, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': '882fe564e3f4ba7e85b6ad1c7542f1e4'}, page_content='What is Machine Learning Pipeline?'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'languages': ['eng'], 'file_directory': 'data', 'filename': 'ml_course.pptx', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'PageBreak', 'element_id': '0815278d05fe9f49c577c0ce610996e8'}, page_content=''),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 3, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': 'e16acab18bc7971064f2d06df301b796'}, page_content='Type of ML Deployment'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 3, 'languages': ['eng'], 'parent_id': 'e16acab18bc7971064f2d06df301b796', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '36a2a2dc69a5a623ccc3eaa559f874eb'}, page_content='Batch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 3, 'languages': ['eng'], 'parent_id': 'e16acab18bc7971064f2d06df301b796', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '16d96a9885601cb65a42510212795d30'}, page_content='Stream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 3, 'languages': ['eng'], 'parent_id': 'e16acab18bc7971064f2d06df301b796', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '04d3ecff9b5d4fe12627ae6f870beb6e'}, page_content='Realtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 3, 'languages': ['eng'], 'parent_id': 'e16acab18bc7971064f2d06df301b796', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': 'f10bcd0ff4058eca301a1322b167df99'}, page_content='Edge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'languages': ['eng'], 'file_directory': 'data', 'filename': 'ml_course.pptx', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'PageBreak', 'element_id': '0815278d05fe9f49c577c0ce610996e8'}, page_content=''),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': 'e3c672c5109e27bd62e12e920f1d27a2'}, page_content='Infrastructure and Integration'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 4, 'languages': ['eng'], 'parent_id': 'e3c672c5109e27bd62e12e920f1d27a2', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '4e5298a16396620c219860a7d5e8ab7c'}, page_content='Hardware and Software: Setting up the right environment for model deployment.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 4, 'languages': ['eng'], 'parent_id': 'e3c672c5109e27bd62e12e920f1d27a2', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '78888da57152041b4442e615b5246edb'}, page_content='Integration: Seamlessly integrating the model with existing systems and applications.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'languages': ['eng'], 'file_directory': 'data', 'filename': 'ml_course.pptx', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'PageBreak', 'element_id': '0815278d05fe9f49c577c0ce610996e8'}, page_content=''),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': '2f1fb082740026e985e63e0ca48f0a57'}, page_content='Benefits of Deploying ML Models'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 5, 'languages': ['eng'], 'parent_id': '2f1fb082740026e985e63e0ca48f0a57', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'NarrativeText', 'element_id': '9306fdd9f8d2398f13dc87e677b5753d'}, page_content='Focus on new models, not maintaining existing models || Prevention of bugs || Creation of records for debugging and reproducing results || Standardization || Allows models to handle real-time data and large user bases.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'languages': ['eng'], 'file_directory': 'data', 'filename': 'ml_course.pptx', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'PageBreak', 'element_id': '0815278d05fe9f49c577c0ce610996e8'}, page_content=''),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': 'a71a94291fbe02b27bb302e9b1a48664'}, page_content='Challenges in ML Deployment'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': 'ba597fa26824eb054d39d8437a79c1d5'}, page_content='Data Management: Making sure the model gets the right kind of data.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '9f213bc7c86c979e37a23b5eedce3ae9'}, page_content='Model Scalability and Performance: Ensuring that their model can effectively scale as it keeps adding more complex information.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': 'bb9713821ae85813bd17a6c463cc3ce6'}, page_content='Integration with Existing Systems: Fitting the model into current computers and software.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '145198c695b5ec2dc6ac53da3cbaa651'}, page_content='Monitoring and Maintenance: Watching and fixing the model over time.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '7823ba8b620067685cc948e52bf31f93'}, page_content='Security and Privacy: Protecting data and keeping it private.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': 'c8a5ca482174cb2fcf841794d148bff1'}, page_content='Resource Management: Using computer resources like memory and power wisely.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '5c6f738bca4aecb944092cf7a71b1607'}, page_content='Versioning and Model Management: Keeping track of different versions of the model.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '7216c33df4dca2c7aa022dc3f491407f'}, page_content='Regulatory Compliance: Making sure the model follows the laws, rules, and regulations.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': 'd58e1f55915272670b32a5befb11d94d'}, page_content='User Acceptance and Trust: Getting people to trust and accept the model.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '5813b7d3380ca2123c8b6487c5089746'}, page_content='Explainability and Transparency: Being able to explain how the model works.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '1a5f2c4918a4f8131903f49fd7631b40'}, page_content='Cost Management: Managing how much it costs to use the model.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 6, 'languages': ['eng'], 'parent_id': 'a71a94291fbe02b27bb302e9b1a48664', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'NarrativeText', 'element_id': 'be5b34f703b2e3c65da27141595f025b'}, page_content='As per research, only 13% of ML models ever make it to production. This is a huge gap, considering the possibilities that AI model deployment can bring to the organization.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'languages': ['eng'], 'file_directory': 'data', 'filename': 'ml_course.pptx', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'PageBreak', 'element_id': '0815278d05fe9f49c577c0ce610996e8'}, page_content=''),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 7, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': 'f7996ce53254adcfcd2a10311f41045f'}, page_content='Data and Model Management'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 7, 'languages': ['eng'], 'parent_id': 'f7996ce53254adcfcd2a10311f41045f', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'NarrativeText', 'element_id': '320f30416dd59fa87347e59a7f4152cc'}, page_content='Data Pipelines: Building and maintaining data pipelines for continuous data flow.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 7, 'languages': ['eng'], 'parent_id': 'f7996ce53254adcfcd2a10311f41045f', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'NarrativeText', 'element_id': 'e646e8776c19f43366fe227a4e0a71e2'}, page_content='Model Versioning: Tracking and managing different versions of models.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'languages': ['eng'], 'file_directory': 'data', 'filename': 'ml_course.pptx', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'PageBreak', 'element_id': '0815278d05fe9f49c577c0ce610996e8'}, page_content=''),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': '1dcc850071d9db7b3b667986bb263816'}, page_content='A/B Testing'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 8, 'languages': ['eng'], 'parent_id': '1dcc850071d9db7b3b667986bb263816', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '3ddd573a708017650792e76df7e4d990'}, page_content='Objective Comparison: A/B testing allows for an objective comparison of two model versions to determine which performs better based on specific metrics.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 8, 'languages': ['eng'], 'parent_id': '1dcc850071d9db7b3b667986bb263816', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '4478afa0de21dcbd03c88592f93c38db'}, page_content='Real-World Application: It is widely used to optimize user experiences, such as testing different recommendation systems or ad strategies to enhance engagement or conversion rates.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 8, 'languages': ['eng'], 'parent_id': '1dcc850071d9db7b3b667986bb263816', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'ListItem', 'element_id': '3ec2a5175d0fee7d38cd787d151f08d9'}, page_content='Statistical Significance: The technique ensures that performance differences are statistically significant and not due to random chance by using control and treatment groups along with statistical tests.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'languages': ['eng'], 'file_directory': 'data', 'filename': 'ml_course.pptx', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'PageBreak', 'element_id': '0815278d05fe9f49c577c0ce610996e8'}, page_content=''),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 1, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 9, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': '5b03acaebcc20ce4ee193be559bb2948'}, page_content='Security, Compliance and Bias'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 9, 'languages': ['eng'], 'parent_id': '5b03acaebcc20ce4ee193be559bb2948', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'NarrativeText', 'element_id': '1faedc7251be5ff2faecd02f54a8924e'}, page_content='Security: Ensuring the security of machine learning models involves protecting sensitive data from unauthorized access and breaches through robust encryption, secure APIs, and access controls'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 9, 'languages': ['eng'], 'parent_id': '5b03acaebcc20ce4ee193be559bb2948', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'NarrativeText', 'element_id': '2e320daf7d90982518b638f2dd11b52a'}, page_content='Compliance: Adhering to industry regulations and standards, such as GDPR or HIPAA, is critical to ensure the legal and ethical use of data in machine learning deployments. This involves data anonymization, user consent, and regular compliance audits.'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 9, 'languages': ['eng'], 'parent_id': '5b03acaebcc20ce4ee193be559bb2948', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'NarrativeText', 'element_id': 'a329e769e4db1267bc11cb90d279edfd'}, page_content='Bias Detection: Identifying and mitigating bias in ML models is crucial to prevent unfair and discriminatory outcomes. This involves using diverse training datasets, applying fairness-aware algorithms, and conducting bias impact assessments'),\n",
       " Document(metadata={'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2024-11-03T21:48:01', 'page_number': 9, 'languages': ['eng'], 'parent_id': '5b03acaebcc20ce4ee193be559bb2948', 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'NarrativeText', 'element_id': 'ae10d92978631de476e6e8a659def9f0'}, page_content='Continuous Monitoring: Regular monitoring and updating of deployed models are essential to maintain security, compliance, and fairness. This involves real-time performance tracking, automated alerts for anomalies, and periodic model retraining.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning Model Deployment'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/ml_course.pptx',\n",
       " 'category_depth': 0,\n",
       " 'file_directory': 'data',\n",
       " 'filename': 'ml_course.pptx',\n",
       " 'last_modified': '2024-11-03T21:48:01',\n",
       " 'page_number': 1,\n",
       " 'languages': ['eng'],\n",
       " 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',\n",
       " 'category': 'Title',\n",
       " 'element_id': '1378fc8ea4dd0830a3c5f93e9d31a516'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Batch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[7].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/ml_course.pptx',\n",
       " 'category_depth': 0,\n",
       " 'file_directory': 'data',\n",
       " 'filename': 'ml_course.pptx',\n",
       " 'last_modified': '2024-11-03T21:48:01',\n",
       " 'page_number': 3,\n",
       " 'languages': ['eng'],\n",
       " 'parent_id': 'e16acab18bc7971064f2d06df301b796',\n",
       " 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',\n",
       " 'category': 'ListItem',\n",
       " 'element_id': '36a2a2dc69a5a623ccc3eaa559f874eb'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[7].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_data = {}\n",
    "\n",
    "for doc in docs:\n",
    "    if isinstance(doc,Document):\n",
    "        page_number = doc.metadata.get('page_number',None)\n",
    "        if page_number:\n",
    "            ppt_data[page_number] = ppt_data.get(page_number,'') + '\\n' + doc.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '\\nMachine Learning Model Deployment\\nIntroduction to ML Pipeline\\nhttps://bit.ly/bert_nlp',\n",
       " 2: '\\nWhat is Machine Learning Pipeline?',\n",
       " 3: '\\nType of ML Deployment\\nBatch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.\\nStream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\\nRealtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.\\nEdge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.',\n",
       " 4: '\\nInfrastructure and Integration\\nHardware and Software: Setting up the right environment for model deployment.\\nIntegration: Seamlessly integrating the model with existing systems and applications.',\n",
       " 5: '\\nBenefits of Deploying ML Models\\nFocus on new models, not maintaining existing models || Prevention of bugs || Creation of records for debugging and reproducing results || Standardization || Allows models to handle real-time data and large user bases.',\n",
       " 6: '\\nChallenges in ML Deployment\\nData Management: Making sure the model gets the right kind of data.\\nModel Scalability and Performance: Ensuring that their model can effectively scale as it keeps adding more complex information.\\nIntegration with Existing Systems: Fitting the model into current computers and software.\\nMonitoring and Maintenance: Watching and fixing the model over time.\\nSecurity and Privacy: Protecting data and keeping it private.\\nResource Management: Using computer resources like memory and power wisely.\\nVersioning and Model Management: Keeping track of different versions of the model.\\nRegulatory Compliance: Making sure the model follows the laws, rules, and regulations.\\nUser Acceptance and Trust: Getting people to trust and accept the model.\\nExplainability and Transparency: Being able to explain how the model works.\\nCost Management: Managing how much it costs to use the model.\\nAs per research, only 13% of ML models ever make it to production. This is a huge gap, considering the possibilities that AI model deployment can bring to the organization.',\n",
       " 7: '\\nData and Model Management\\nData Pipelines: Building and maintaining data pipelines for continuous data flow.\\nModel Versioning: Tracking and managing different versions of models.',\n",
       " 8: '\\nA/B Testing\\nObjective Comparison: A/B testing allows for an objective comparison of two model versions to determine which performs better based on specific metrics.\\nReal-World Application: It is widely used to optimize user experiences, such as testing different recommendation systems or ad strategies to enhance engagement or conversion rates.\\nStatistical Significance: The technique ensures that performance differences are statistically significant and not due to random chance by using control and treatment groups along with statistical tests.',\n",
       " 9: '\\nSecurity, Compliance and Bias\\nSecurity: Ensuring the security of machine learning models involves protecting sensitive data from unauthorized access and breaches through robust encryption, secure APIs, and access controls\\nCompliance: Adhering to industry regulations and standards, such as GDPR or HIPAA, is critical to ensure the legal and ethical use of data in machine learning deployments. This involves data anonymization, user consent, and regular compliance audits.\\nBias Detection: Identifying and mitigating bias in ML models is crucial to prevent unfair and discriminatory outcomes. This involves using diverse training datasets, applying fairness-aware algorithms, and conducting bias impact assessments\\nContinuous Monitoring: Regular monitoring and updating of deployed models are essential to maintain security, compliance, and fairness. This involves real-time performance tracking, automated alerts for anomalies, and periodic model retraining.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type of ML Deployment\n",
      "Batch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.\n",
      "Stream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\n",
      "Realtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.\n",
      "Edge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.\n"
     ]
    }
   ],
   "source": [
    "print(ppt_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ppt_data(file_path: str, mode: str = 'elements', verbose: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts content from a PowerPoint file and organizes it by page number.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PowerPoint file.\n",
    "        mode (str): Mode for loading the PowerPoint file. Default is 'elements'.\n",
    "        verbose (bool): If True, displays progress messages. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are page numbers and values are the concatenated content of each page.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the file path is invalid.\n",
    "        ValueError: If the loader fails to process the file.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Initializing UnstructuredPowerPointLoader with file: {file_path} and mode: {mode}...\")\n",
    "\n",
    "    try:\n",
    "        loader = UnstructuredPowerPointLoader(file_path=file_path, mode=mode)\n",
    "        docs = loader.load()\n",
    "        if verbose:\n",
    "            print(f\"Successfully loaded {len(docs)} documents.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to load PowerPoint file. Error: {str(e)}\")\n",
    "\n",
    "    ppt_data = {}\n",
    "\n",
    "    for idx, doc in enumerate(docs, start=1):\n",
    "        if isinstance(doc, Document):\n",
    "            page_number = doc.metadata.get('page_number', None)\n",
    "            if page_number:\n",
    "                ppt_data[page_number] = ppt_data.get(page_number, '') + '\\n' + doc.page_content\n",
    "            if verbose:\n",
    "                print(f\"Processed document {idx}/{len(docs)}: Page {page_number if page_number else 'break'}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Extraction complete.\")\n",
    "\n",
    "    return ppt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing UnstructuredPowerPointLoader with file: data/ml_course.pptx and mode: elements...\n",
      "Successfully loaded 47 documents.\n",
      "Processed document 1/47: Page 1\n",
      "Processed document 2/47: Page 1\n",
      "Processed document 3/47: Page 1\n",
      "Processed document 4/47: Page break\n",
      "Processed document 5/47: Page 2\n",
      "Processed document 6/47: Page break\n",
      "Processed document 7/47: Page 3\n",
      "Processed document 8/47: Page 3\n",
      "Processed document 9/47: Page 3\n",
      "Processed document 10/47: Page 3\n",
      "Processed document 11/47: Page 3\n",
      "Processed document 12/47: Page break\n",
      "Processed document 13/47: Page 4\n",
      "Processed document 14/47: Page 4\n",
      "Processed document 15/47: Page 4\n",
      "Processed document 16/47: Page break\n",
      "Processed document 17/47: Page 5\n",
      "Processed document 18/47: Page 5\n",
      "Processed document 19/47: Page break\n",
      "Processed document 20/47: Page 6\n",
      "Processed document 21/47: Page 6\n",
      "Processed document 22/47: Page 6\n",
      "Processed document 23/47: Page 6\n",
      "Processed document 24/47: Page 6\n",
      "Processed document 25/47: Page 6\n",
      "Processed document 26/47: Page 6\n",
      "Processed document 27/47: Page 6\n",
      "Processed document 28/47: Page 6\n",
      "Processed document 29/47: Page 6\n",
      "Processed document 30/47: Page 6\n",
      "Processed document 31/47: Page 6\n",
      "Processed document 32/47: Page 6\n",
      "Processed document 33/47: Page break\n",
      "Processed document 34/47: Page 7\n",
      "Processed document 35/47: Page 7\n",
      "Processed document 36/47: Page 7\n",
      "Processed document 37/47: Page break\n",
      "Processed document 38/47: Page 8\n",
      "Processed document 39/47: Page 8\n",
      "Processed document 40/47: Page 8\n",
      "Processed document 41/47: Page 8\n",
      "Processed document 42/47: Page break\n",
      "Processed document 43/47: Page 9\n",
      "Processed document 44/47: Page 9\n",
      "Processed document 45/47: Page 9\n",
      "Processed document 46/47: Page 9\n",
      "Processed document 47/47: Page 9\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "ppt_data = extract_ppt_data(file_path=\"data/ml_course.pptx\",mode='elements',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '\\nMachine Learning Model Deployment\\nIntroduction to ML Pipeline\\nhttps://bit.ly/bert_nlp',\n",
       " 2: '\\nWhat is Machine Learning Pipeline?',\n",
       " 3: '\\nType of ML Deployment\\nBatch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.\\nStream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\\nRealtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.\\nEdge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.',\n",
       " 4: '\\nInfrastructure and Integration\\nHardware and Software: Setting up the right environment for model deployment.\\nIntegration: Seamlessly integrating the model with existing systems and applications.',\n",
       " 5: '\\nBenefits of Deploying ML Models\\nFocus on new models, not maintaining existing models || Prevention of bugs || Creation of records for debugging and reproducing results || Standardization || Allows models to handle real-time data and large user bases.',\n",
       " 6: '\\nChallenges in ML Deployment\\nData Management: Making sure the model gets the right kind of data.\\nModel Scalability and Performance: Ensuring that their model can effectively scale as it keeps adding more complex information.\\nIntegration with Existing Systems: Fitting the model into current computers and software.\\nMonitoring and Maintenance: Watching and fixing the model over time.\\nSecurity and Privacy: Protecting data and keeping it private.\\nResource Management: Using computer resources like memory and power wisely.\\nVersioning and Model Management: Keeping track of different versions of the model.\\nRegulatory Compliance: Making sure the model follows the laws, rules, and regulations.\\nUser Acceptance and Trust: Getting people to trust and accept the model.\\nExplainability and Transparency: Being able to explain how the model works.\\nCost Management: Managing how much it costs to use the model.\\nAs per research, only 13% of ML models ever make it to production. This is a huge gap, considering the possibilities that AI model deployment can bring to the organization.',\n",
       " 7: '\\nData and Model Management\\nData Pipelines: Building and maintaining data pipelines for continuous data flow.\\nModel Versioning: Tracking and managing different versions of models.',\n",
       " 8: '\\nA/B Testing\\nObjective Comparison: A/B testing allows for an objective comparison of two model versions to determine which performs better based on specific metrics.\\nReal-World Application: It is widely used to optimize user experiences, such as testing different recommendation systems or ad strategies to enhance engagement or conversion rates.\\nStatistical Significance: The technique ensures that performance differences are statistically significant and not due to random chance by using control and treatment groups along with statistical tests.',\n",
       " 9: '\\nSecurity, Compliance and Bias\\nSecurity: Ensuring the security of machine learning models involves protecting sensitive data from unauthorized access and breaches through robust encryption, secure APIs, and access controls\\nCompliance: Adhering to industry regulations and standards, such as GDPR or HIPAA, is critical to ensure the legal and ethical use of data in machine learning deployments. This involves data anonymization, user consent, and regular compliance audits.\\nBias Detection: Identifying and mitigating bias in ML models is crucial to prevent unfair and discriminatory outcomes. This involves using diverse training datasets, applying fairness-aware algorithms, and conducting bias impact assessments\\nContinuous Monitoring: Regular monitoring and updating of deployed models are essential to maintain security, compliance, and fairness. This involves real-time performance tracking, automated alerts for anomalies, and periodic model retraining.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "\n",
    "for page_number, page_content in ppt_data.items():\n",
    "    context += f\"### Page-{page_number}{page_content}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Page-1\n",
      "Machine Learning Model Deployment\n",
      "Introduction to ML Pipeline\n",
      "https://bit.ly/bert_nlp\n",
      "\n",
      "### Page-2\n",
      "What is Machine Learning Pipeline?\n",
      "\n",
      "### Page-3\n",
      "Type of ML Deployment\n",
      "Batch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.\n",
      "Stream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\n",
      "Realtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.\n",
      "Edge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.\n",
      "\n",
      "### Page-4\n",
      "Infrastructure and Integration\n",
      "Hardware and Software: Setting up the right environment for model deployment.\n",
      "Integration: Seamlessly integrating the model with existing systems and applications.\n",
      "\n",
      "### Page-5\n",
      "Benefits of Deploying ML Models\n",
      "Focus on new models, not maintaining existing models || Prevention of bugs || Creation of records for debugging and reproducing results || Standardization || Allows models to handle real-time data and large user bases.\n",
      "\n",
      "### Page-6\n",
      "Challenges in ML Deployment\n",
      "Data Management: Making sure the model gets the right kind of data.\n",
      "Model Scalability and Performance: Ensuring that their model can effectively scale as it keeps adding more complex information.\n",
      "Integration with Existing Systems: Fitting the model into current computers and software.\n",
      "Monitoring and Maintenance: Watching and fixing the model over time.\n",
      "Security and Privacy: Protecting data and keeping it private.\n",
      "Resource Management: Using computer resources like memory and power wisely.\n",
      "Versioning and Model Management: Keeping track of different versions of the model.\n",
      "Regulatory Compliance: Making sure the model follows the laws, rules, and regulations.\n",
      "User Acceptance and Trust: Getting people to trust and accept the model.\n",
      "Explainability and Transparency: Being able to explain how the model works.\n",
      "Cost Management: Managing how much it costs to use the model.\n",
      "As per research, only 13% of ML models ever make it to production. This is a huge gap, considering the possibilities that AI model deployment can bring to the organization.\n",
      "\n",
      "### Page-7\n",
      "Data and Model Management\n",
      "Data Pipelines: Building and maintaining data pipelines for continuous data flow.\n",
      "Model Versioning: Tracking and managing different versions of models.\n",
      "\n",
      "### Page-8\n",
      "A/B Testing\n",
      "Objective Comparison: A/B testing allows for an objective comparison of two model versions to determine which performs better based on specific metrics.\n",
      "Real-World Application: It is widely used to optimize user experiences, such as testing different recommendation systems or ad strategies to enhance engagement or conversion rates.\n",
      "Statistical Significance: The technique ensures that performance differences are statistically significant and not due to random chance by using control and treatment groups along with statistical tests.\n",
      "\n",
      "### Page-9\n",
      "Security, Compliance and Bias\n",
      "Security: Ensuring the security of machine learning models involves protecting sensitive data from unauthorized access and breaches through robust encryption, secure APIs, and access controls\n",
      "Compliance: Adhering to industry regulations and standards, such as GDPR or HIPAA, is critical to ensure the legal and ethical use of data in machine learning deployments. This involves data anonymization, user consent, and regular compliance audits.\n",
      "Bias Detection: Identifying and mitigating bias in ML models is crucial to prevent unfair and discriminatory outcomes. This involves using diverse training datasets, applying fairness-aware algorithms, and conducting bias impact assessments\n",
      "Continuous Monitoring: Regular monitoring and updating of deployed models are essential to maintain security, compliance, and fairness. This involves real-time performance tracking, automated alerts for anomalies, and periodic model retraining.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_from_ppt_data(ppt_data: dict, verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Builds a formatted context string from PowerPoint data organized by page number.\n",
    "\n",
    "    Args:\n",
    "        ppt_data (dict): A dictionary where keys are page numbers (int) and \n",
    "                         values are the corresponding page content (str).\n",
    "        verbose (bool): If True, displays progress messages. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted context string with page information.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `ppt_data` is empty or not a dictionary.\n",
    "    \"\"\"\n",
    "    if not isinstance(ppt_data, dict):\n",
    "        raise ValueError(\"Invalid input: `ppt_data` must be a dictionary.\")\n",
    "    if not ppt_data:\n",
    "        raise ValueError(\"Invalid input: `ppt_data` cannot be empty.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Building context from PowerPoint data...\")\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for page_number, page_content in sorted(ppt_data.items()):\n",
    "        if not isinstance(page_number, int):\n",
    "            if verbose:\n",
    "                print(f\"Skipping invalid page number: {page_number}\")\n",
    "            continue\n",
    "        if not isinstance(page_content, str):\n",
    "            if verbose:\n",
    "                print(f\"Skipping invalid page content for page {page_number}\")\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Adding content for Page-{page_number}...\")\n",
    "\n",
    "        context += f\"### Page-{page_number}\\n{page_content.strip()}\\n\\n\"\n",
    "\n",
    "    if not context:\n",
    "        raise ValueError(\"Context generation failed: No valid content found in `ppt_data`.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Context generation complete.\")\n",
    "    \n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building context from PowerPoint data...\n",
      "Adding content for Page-1...\n",
      "Adding content for Page-2...\n",
      "Adding content for Page-3...\n",
      "Adding content for Page-4...\n",
      "Adding content for Page-5...\n",
      "Adding content for Page-6...\n",
      "Adding content for Page-7...\n",
      "Adding content for Page-8...\n",
      "Adding content for Page-9...\n",
      "Context generation complete.\n"
     ]
    }
   ],
   "source": [
    "context = build_context_from_ppt_data(ppt_data=ppt_data,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Page-1\n",
      "Machine Learning Model Deployment\n",
      "Introduction to ML Pipeline\n",
      "https://bit.ly/bert_nlp\n",
      "\n",
      "### Page-2\n",
      "What is Machine Learning Pipeline?\n",
      "\n",
      "### Page-3\n",
      "Type of ML Deployment\n",
      "Batch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.\n",
      "Stream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\n",
      "Realtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.\n",
      "Edge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.\n",
      "\n",
      "### Page-4\n",
      "Infrastructure and Integration\n",
      "Hardware and Software: Setting up the right environment for model deployment.\n",
      "Integration: Seamlessly integrating the model with existing systems and applications.\n",
      "\n",
      "### Page-5\n",
      "Benefits of Deploying ML Models\n",
      "Focus on new models, not maintaining existing models || Prevention of bugs || Creation of records for debugging and reproducing results || Standardization || Allows models to handle real-time data and large user bases.\n",
      "\n",
      "### Page-6\n",
      "Challenges in ML Deployment\n",
      "Data Management: Making sure the model gets the right kind of data.\n",
      "Model Scalability and Performance: Ensuring that their model can effectively scale as it keeps adding more complex information.\n",
      "Integration with Existing Systems: Fitting the model into current computers and software.\n",
      "Monitoring and Maintenance: Watching and fixing the model over time.\n",
      "Security and Privacy: Protecting data and keeping it private.\n",
      "Resource Management: Using computer resources like memory and power wisely.\n",
      "Versioning and Model Management: Keeping track of different versions of the model.\n",
      "Regulatory Compliance: Making sure the model follows the laws, rules, and regulations.\n",
      "User Acceptance and Trust: Getting people to trust and accept the model.\n",
      "Explainability and Transparency: Being able to explain how the model works.\n",
      "Cost Management: Managing how much it costs to use the model.\n",
      "As per research, only 13% of ML models ever make it to production. This is a huge gap, considering the possibilities that AI model deployment can bring to the organization.\n",
      "\n",
      "### Page-7\n",
      "Data and Model Management\n",
      "Data Pipelines: Building and maintaining data pipelines for continuous data flow.\n",
      "Model Versioning: Tracking and managing different versions of models.\n",
      "\n",
      "### Page-8\n",
      "A/B Testing\n",
      "Objective Comparison: A/B testing allows for an objective comparison of two model versions to determine which performs better based on specific metrics.\n",
      "Real-World Application: It is widely used to optimize user experiences, such as testing different recommendation systems or ad strategies to enhance engagement or conversion rates.\n",
      "Statistical Significance: The technique ensures that performance differences are statistically significant and not due to random chance by using control and treatment groups along with statistical tests.\n",
      "\n",
      "### Page-9\n",
      "Security, Compliance and Bias\n",
      "Security: Ensuring the security of machine learning models involves protecting sensitive data from unauthorized access and breaches through robust encryption, secure APIs, and access controls\n",
      "Compliance: Adhering to industry regulations and standards, such as GDPR or HIPAA, is critical to ensure the legal and ethical use of data in machine learning deployments. This involves data anonymization, user consent, and regular compliance audits.\n",
      "Bias Detection: Identifying and mitigating bias in ML models is crucial to prevent unfair and discriminatory outcomes. This involves using diverse training datasets, applying fairness-aware algorithms, and conducting bias impact assessments\n",
      "Continuous Monitoring: Regular monitoring and updating of deployed models are essential to maintain security, compliance, and fairness. This involves real-time performance tracking, automated alerts for anomalies, and periodic model retraining.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import ask_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a script for a 2-minute presentation based on the provided PowerPoint slides:\n",
      "\n",
      "**Slide 1: Introduction to ML Pipeline**\n",
      "\n",
      "\"Good morning everyone, and welcome to our presentation on Machine Learning Model Deployment. As we all know, machine learning has revolutionized the way we approach complex problems in various industries. But have you ever wondered what it takes to get a machine learning model from development to production? Today, we'll take you through the journey of ML pipeline deployment, and explore the key considerations that come with it.\"\n",
      "\n",
      "**Slide 2: What is Machine Learning Pipeline?**\n",
      "\n",
      "\"So, what exactly is an ML pipeline? Simply put, an ML pipeline refers to the process of building, testing, and deploying a machine learning model. It's like a manufacturing line for AI models. Just as a car goes through various stages of production, from design to assembly, an ML pipeline takes a model through different stages of development, validation, and deployment.\"\n",
      "\n",
      "**Slide 3: Type of ML Deployment**\n",
      "\n",
      "\"Now, let's talk about the types of ML deployments. We have batch, stream, realtime, and edge deployment. Each type has its own use case and advantage. Batch deployment is ideal for end-of-day reporting or monthly analytics. Stream deployment is perfect for applications like fraud detection or live social media analysis. Realtime deployment provides instant predictions or decisions in response to incoming data, while edge deployment runs ML models on local devices close to the data source.\"\n",
      "\n",
      "**Script pause for 30 seconds**\n",
      "\n",
      "**Slide 4: Infrastructure and Integration**\n",
      "\n",
      "\"Next, we need to talk about infrastructure and integration. Setting up the right environment is crucial for model deployment. We're talking hardware and software, as well as integrating our model with existing systems and applications. This requires careful planning and consideration of scalability, performance, and security.\"\n",
      "\n",
      "**Script pause for 30 seconds**\n",
      "\n",
      "**Slide 5: Benefits of Deploying ML Models**\n",
      "\n",
      "\"So, what are the benefits of deploying machine learning models? Well, it allows us to focus on new models rather than maintaining existing ones. It also prevents bugs and creates records for debugging and reproducing results. Standardization is another key advantage, as our models can handle real-time data and large user bases.\"\n",
      "\n",
      "**Script pause for 30 seconds**\n",
      "\n",
      "**Slide 6: Challenges in ML Deployment**\n",
      "\n",
      "\"Now, let's talk about the challenges we face in ML deployment. Data management is a big one – ensuring that our model gets the right kind of data. Model scalability and performance are also critical considerations. Integration with existing systems, monitoring and maintenance, security and privacy, resource management, versioning and model management, regulatory compliance, user acceptance and trust, explainability and transparency, cost management... the list goes on.\"\n",
      "\n",
      "**Script pause for 30 seconds**\n",
      "\n",
      "**Slide 7: Data and Model Management**\n",
      "\n",
      "\"Data pipelines are essential for continuous data flow, while model versioning helps us track different versions of models. By managing our data and models effectively, we can ensure that our ML pipeline is running smoothly and efficiently.\"\n",
      "\n",
      "**Script pause for 30 seconds**\n",
      "\n",
      "**Slide 8: A/B Testing**\n",
      "\n",
      "\"A/B testing allows us to compare two model versions objectively and determine which performs better based on specific metrics. It's widely used in applications like recommendation systems or ad strategies to optimize user experiences.\"\n",
      "\n",
      "**Script pause for 30 seconds**\n",
      "\n",
      "**Slide 9: Security, Compliance and Bias**\n",
      "\n",
      "\"Finally, we need to talk about security, compliance, and bias. Ensuring the security of our models is crucial – protecting sensitive data from unauthorized access and breaches. We also need to adhere to industry regulations and standards like GDPR or HIPAA. And of course, identifying and mitigating bias in ML models is critical to prevent unfair and discriminatory outcomes.\"\n",
      "\n",
      "**Script pause for 30 seconds**\n",
      "\n",
      "\"I hope that concludes our presentation on machine learning model deployment. It's a complex journey, but with careful planning and consideration, we can unlock the full potential of AI models in our organization.\"\n"
     ]
    }
   ],
   "source": [
    "question =\"\"\"\n",
    "For each PowerPoint slide provided above, write a 2-minute script that effectively conveys the key points.\n",
    "Ensure a smooth flow between slides, maintaining a clear and engaging narrative.\n",
    "\"\"\"\n",
    "\n",
    "response = ask_llm(context=context,\n",
    "                   question=question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ppt_script.md\", \"w\") as f:\n",
    "    f.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "from scripts import ask_llm\n",
    "\n",
    "\n",
    "def extract_ppt_data(file_path: str, mode: str = 'elements', verbose: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts content from a PowerPoint file and organizes it by page number.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PowerPoint file.\n",
    "        mode (str): Mode for loading the PowerPoint file. Default is 'elements'.\n",
    "        verbose (bool): If True, displays progress messages. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are page numbers and values are the concatenated content of each page.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the file path is invalid.\n",
    "        ValueError: If the loader fails to process the file.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Initializing UnstructuredPowerPointLoader with file: {file_path} and mode: {mode}...\")\n",
    "\n",
    "    try:\n",
    "        loader = UnstructuredPowerPointLoader(file_path=file_path, mode=mode)\n",
    "        docs = loader.load()\n",
    "        if verbose:\n",
    "            print(f\"Successfully loaded {len(docs)} documents.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to load PowerPoint file. Error: {str(e)}\")\n",
    "\n",
    "    ppt_data = {}\n",
    "\n",
    "    for idx, doc in enumerate(docs, start=1):\n",
    "        if isinstance(doc, Document):\n",
    "            page_number = doc.metadata.get('page_number', None)\n",
    "            if page_number:\n",
    "                ppt_data[page_number] = ppt_data.get(page_number, '') + '\\n' + doc.page_content\n",
    "            if verbose:\n",
    "                print(f\"Processed document {idx}/{len(docs)}: Page {page_number if page_number else 'break'}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Extraction complete.\")\n",
    "\n",
    "    return ppt_data\n",
    "\n",
    "def build_context_from_ppt_data(ppt_data: dict, verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Builds a formatted context string from PowerPoint data organized by page number.\n",
    "\n",
    "    Args:\n",
    "        ppt_data (dict): A dictionary where keys are page numbers (int) and \n",
    "                         values are the corresponding page content (str).\n",
    "        verbose (bool): If True, displays progress messages. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted context string with page information.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `ppt_data` is empty or not a dictionary.\n",
    "    \"\"\"\n",
    "    if not isinstance(ppt_data, dict):\n",
    "        raise ValueError(\"Invalid input: `ppt_data` must be a dictionary.\")\n",
    "    if not ppt_data:\n",
    "        raise ValueError(\"Invalid input: `ppt_data` cannot be empty.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Building context from PowerPoint data...\")\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for page_number, page_content in sorted(ppt_data.items()):\n",
    "        if not isinstance(page_number, int):\n",
    "            if verbose:\n",
    "                print(f\"Skipping invalid page number: {page_number}\")\n",
    "            continue\n",
    "        if not isinstance(page_content, str):\n",
    "            if verbose:\n",
    "                print(f\"Skipping invalid page content for page {page_number}\")\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Adding content for Page-{page_number}...\")\n",
    "\n",
    "        context += f\"### Page-{page_number}\\n{page_content.strip()}\\n\\n\"\n",
    "\n",
    "    if not context:\n",
    "        raise ValueError(\"Context generation failed: No valid content found in `ppt_data`.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Context generation complete.\")\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def get_script_for_ppt(\n",
    "    file_path: str,\n",
    "    mode: str,\n",
    "    question: str,\n",
    "    save_and_display: bool = False,\n",
    "    save: bool = False,\n",
    "    save_file_path: str = \"data/ppt_script.md\",\n",
    "    verbose: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generates a script for a PowerPoint presentation by extracting data, building context, and querying an LLM.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PowerPoint file.\n",
    "        mode (str): Mode for loading the PowerPoint file (e.g., 'elements').\n",
    "        question (str): Question to query the LLM with.\n",
    "        save_and_display (bool): If True, saves the response to a file and returns it. Default is False.\n",
    "        save (bool): If True, saves the response to a file. Ignored if `save_and_display` is True. Default is False.\n",
    "        save_file_path (str): Path to save the generated script. Default is \"data/ppt_script.md\".\n",
    "        verbose (bool): If True, displays progress and debugging messages. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from the LLM if not saved.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the PowerPoint file does not exist.\n",
    "        ValueError: If an invalid mode or empty question is provided.\n",
    "        Exception: For other unexpected errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if verbose:\n",
    "            print(\"Starting script generation...\")\n",
    "\n",
    "        # Validate inputs\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"The specified PowerPoint file does not exist: {file_path}\")\n",
    "        if not isinstance(mode, str) or not mode.strip():\n",
    "            raise ValueError(\"Invalid mode provided. Mode must be a non-empty string.\")\n",
    "        if not isinstance(question, str) or not question.strip():\n",
    "            raise ValueError(\"Invalid question provided. Question must be a non-empty string.\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Extracting data from file: {file_path} using mode: {mode}...\")\n",
    "\n",
    "        # Extract PowerPoint data\n",
    "        ppt_data = extract_ppt_data(file_path=file_path, mode=mode, verbose=verbose)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Building context from extracted data...\")\n",
    "\n",
    "        # Build context\n",
    "        context = build_context_from_ppt_data(ppt_data=ppt_data, verbose=verbose)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Querying the LLM for response...\")\n",
    "\n",
    "        # Query LLM\n",
    "        response = ask_llm(context=context, question=question)\n",
    "\n",
    "        # Handle saving and/or returning the response\n",
    "        if save_and_display or save:\n",
    "            os.makedirs(os.path.dirname(save_file_path), exist_ok=True)\n",
    "            with open(save_file_path, \"w\") as f:\n",
    "                f.write(response)\n",
    "            if verbose:\n",
    "                print(f\"Response saved to: {save_file_path}\")\n",
    "\n",
    "        if save_and_display:\n",
    "            return response\n",
    "        elif not save:\n",
    "            return response\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Script generation complete.\")\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        raise FileNotFoundError(f\"File error: {fnf_error}\")\n",
    "    except ValueError as val_error:\n",
    "        raise ValueError(f\"Validation error: {val_error}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An unexpected error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script generation...\n",
      "Extracting data from file: data/ml_course.pptx using mode: elements...\n",
      "Initializing UnstructuredPowerPointLoader with file: data/ml_course.pptx and mode: elements...\n",
      "Successfully loaded 47 documents.\n",
      "Processed document 1/47: Page 1\n",
      "Processed document 2/47: Page 1\n",
      "Processed document 3/47: Page 1\n",
      "Processed document 4/47: Page break\n",
      "Processed document 5/47: Page 2\n",
      "Processed document 6/47: Page break\n",
      "Processed document 7/47: Page 3\n",
      "Processed document 8/47: Page 3\n",
      "Processed document 9/47: Page 3\n",
      "Processed document 10/47: Page 3\n",
      "Processed document 11/47: Page 3\n",
      "Processed document 12/47: Page break\n",
      "Processed document 13/47: Page 4\n",
      "Processed document 14/47: Page 4\n",
      "Processed document 15/47: Page 4\n",
      "Processed document 16/47: Page break\n",
      "Processed document 17/47: Page 5\n",
      "Processed document 18/47: Page 5\n",
      "Processed document 19/47: Page break\n",
      "Processed document 20/47: Page 6\n",
      "Processed document 21/47: Page 6\n",
      "Processed document 22/47: Page 6\n",
      "Processed document 23/47: Page 6\n",
      "Processed document 24/47: Page 6\n",
      "Processed document 25/47: Page 6\n",
      "Processed document 26/47: Page 6\n",
      "Processed document 27/47: Page 6\n",
      "Processed document 28/47: Page 6\n",
      "Processed document 29/47: Page 6\n",
      "Processed document 30/47: Page 6\n",
      "Processed document 31/47: Page 6\n",
      "Processed document 32/47: Page 6\n",
      "Processed document 33/47: Page break\n",
      "Processed document 34/47: Page 7\n",
      "Processed document 35/47: Page 7\n",
      "Processed document 36/47: Page 7\n",
      "Processed document 37/47: Page break\n",
      "Processed document 38/47: Page 8\n",
      "Processed document 39/47: Page 8\n",
      "Processed document 40/47: Page 8\n",
      "Processed document 41/47: Page 8\n",
      "Processed document 42/47: Page break\n",
      "Processed document 43/47: Page 9\n",
      "Processed document 44/47: Page 9\n",
      "Processed document 45/47: Page 9\n",
      "Processed document 46/47: Page 9\n",
      "Processed document 47/47: Page 9\n",
      "Extraction complete.\n",
      "Building context from extracted data...\n",
      "Building context from PowerPoint data...\n",
      "Adding content for Page-1...\n",
      "Adding content for Page-2...\n",
      "Adding content for Page-3...\n",
      "Adding content for Page-4...\n",
      "Adding content for Page-5...\n",
      "Adding content for Page-6...\n",
      "Adding content for Page-7...\n",
      "Adding content for Page-8...\n",
      "Adding content for Page-9...\n",
      "Context generation complete.\n",
      "Querying the LLM for response...\n",
      "Response saved to: data/ppt_script.md\n",
      "Here is a 2-minute script for each PowerPoint slide:\n",
      "\n",
      "**Slide 1: Machine Learning Model Deployment**\n",
      "\n",
      "Good morning everyone, and welcome to our presentation on machine learning model deployment. In today's data-driven world, deploying machine learning models is crucial for organizations to gain a competitive edge. But what exactly is machine learning pipeline? (pause for emphasis) A machine learning pipeline is the process of building, training, and deploying a machine learning model into production. It's a continuous cycle that ensures our models are accurate, reliable, and scalable.\n",
      "\n",
      "(pause for 5 seconds)\n",
      "\n",
      "We'll explore different types of deployment in this presentation, including batch, stream, realtime, and edge deployment. Each type has its unique characteristics and use cases, and we'll dive into the specifics of each one.\n",
      "\n",
      "(motion to next slide)\n",
      "\n",
      "**Slide 2: What is Machine Learning Pipeline?**\n",
      "\n",
      "So, what exactly is a machine learning pipeline? (pause for emphasis) It's a series of processes that transform raw data into actionable insights. The pipeline includes data ingestion, preprocessing, modeling, evaluation, and deployment. Each step builds upon the previous one to create a robust and accurate model.\n",
      "\n",
      "(pause for 5 seconds)\n",
      "\n",
      "A well-designed pipeline ensures that our models are reliable, efficient, and scalable. It's a critical component of any machine learning strategy, and we'll explore how to build and maintain a successful pipeline in this presentation.\n",
      "\n",
      "(motion to next slide)\n",
      "\n",
      "**Slide 3: Type of ML Deployment**\n",
      "\n",
      "Now, let's talk about the different types of deployment available. (pause for emphasis) We have batch deployment, which is ideal for tasks like end-of-day reporting or monthly analytics. In stream deployment, models process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\n",
      "\n",
      "(pause for 5 seconds)\n",
      "\n",
      "Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving. And edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, crucial for IoT applications and smart devices.\n",
      "\n",
      "(motion to next slide)\n",
      "\n",
      "**Slide 4: Infrastructure and Integration**\n",
      "\n",
      "Setting up the right environment for model deployment is critical. (pause for emphasis) We need to ensure that our infrastructure is scalable, secure, and reliable. This includes hardware and software setup, as well as integration with existing systems and applications.\n",
      "\n",
      "(pause for 5 seconds)\n",
      "\n",
      "Seamless integration enables us to deploy models quickly and efficiently, without disrupting the workflow of our users. And by leveraging cloud-based services, we can scale our deployment capabilities to meet growing demands.\n",
      "\n",
      "(motion to next slide)\n",
      "\n",
      "**Slide 5: Benefits of Deploying ML Models**\n",
      "\n",
      "Deploying machine learning models brings numerous benefits to organizations. (pause for emphasis) We can focus on new models, rather than maintaining existing ones. This frees up resources and allows us to innovate more quickly.\n",
      "\n",
      "(pause for 5 seconds)\n",
      "\n",
      "We also prevent bugs from entering our systems, create records for debugging and reproducing results, standardize processes, and enable models to handle real-time data and large user bases. These benefits are critical to driving business success in today's competitive landscape.\n",
      "\n",
      "(motion to next slide)\n",
      "\n",
      "**Slide 6: Challenges in ML Deployment**\n",
      "\n",
      "However, deploying machine learning models also presents several challenges. (pause for emphasis) We need to ensure that our model gets the right kind of data, scale effectively as it adds more complex information, and integrate with existing systems seamlessly.\n",
      "\n",
      "(pause for 5 seconds)\n",
      "\n",
      "We must also monitor and maintain our models over time, protect sensitive data from unauthorized access, and comply with industry regulations. These challenges are critical to avoiding errors, ensuring security, and maintaining compliance.\n",
      "\n",
      "(motion to next slide)\n",
      "\n",
      "**Slide 7: Data and Model Management**\n",
      "\n",
      "Effective data management is crucial for successful ML deployment. (pause for emphasis) We need to build and maintain data pipelines for continuous data flow, track and manage different versions of models, and ensure data quality and integrity.\n",
      "\n",
      "(pause for 5 seconds)\n",
      "\n",
      "By leveraging advanced data technologies like data warehouses and NoSQL databases, we can create a robust and scalable data management system that supports our ML deployment strategy.\n",
      "\n",
      "(motion to next slide)\n",
      "\n",
      "**Slide 8: A/B Testing**\n",
      "\n",
      "A/B testing is critical for optimizing model performance. (pause for emphasis) It allows us to compare different model versions, identify areas of improvement, and refine our models to deliver better results.\n",
      "\n",
      "(pause for 5 seconds)\n",
      "\n",
      "By leveraging advanced statistical techniques and real-world applications, we can ensure that our model performance differences are statistically significant and not due to random chance.\n",
      "\n",
      "(motion to next slide)\n",
      "\n",
      "**Slide 9: Security, Compliance and Bias**\n",
      "\n",
      "Finally, we need to address security, compliance, and bias concerns in our ML deployment strategy. (pause for emphasis) We must ensure the security of sensitive data from unauthorized access and breaches, adhere to industry regulations and standards, and detect and mitigate bias in our models.\n",
      "\n",
      "(pause for 5 seconds)\n",
      "\n",
      "By leveraging advanced security technologies like encryption and secure APIs, we can protect our data and ensure compliance with industry regulations. And by using fairness-aware algorithms and conducting bias impact assessments, we can ensure that our models are fair and unbiased.\n",
      "\n",
      "(motion to end of presentation)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/ml_course.pptx\"\n",
    "mode = 'elements'\n",
    "question =\"\"\"For each PowerPoint slide provided above, write a 2-minute script that effectively conveys the key points.\n",
    "    Ensure a smooth flow between slides, maintaining a clear and engaging narrative.\n",
    "    \"\"\"\n",
    "save = False\n",
    "save_file_path = \"data/ppt_script.md\"\n",
    "\n",
    "\n",
    "script = get_script_for_ppt(file_path=file_path,mode=mode,question=question,save_and_display=True,save_file_path=save_file_path,verbose=True)\n",
    "\n",
    "print(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 2: Excel Data Analysis with LLM \n",
    "**Note:** Currently LLMs are not good in Math and Data Analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredExcelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredExcelLoader(file_path=\"data/sample.xlsx\",mode='elements')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nFirst Name\\nLast Name\\nCity\\nGender\\n\\n\\nBrandon\\nJames\\nMiami\\nM\\n\\n\\nSean\\nHawkins\\nDenver\\nM\\n\\n\\nJudy\\nDay\\nLos Angeles\\nF\\n\\n\\nAshley\\nRuiz\\nSan Francisco\\nF\\n\\n\\nStephanie\\nGomez\\nPortland\\nF\\n\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/sample.xlsx',\n",
       " 'file_directory': 'data',\n",
       " 'filename': 'sample.xlsx',\n",
       " 'last_modified': '2024-11-03T21:48:01',\n",
       " 'page_name': 'Data',\n",
       " 'page_number': 1,\n",
       " 'text_as_html': '<table border=\"1\" class=\"dataframe\">\\n  <tbody>\\n    <tr>\\n      <td>First Name</td>\\n      <td>Last Name</td>\\n      <td>City</td>\\n      <td>Gender</td>\\n    </tr>\\n    <tr>\\n      <td>Brandon</td>\\n      <td>James</td>\\n      <td>Miami</td>\\n      <td>M</td>\\n    </tr>\\n    <tr>\\n      <td>Sean</td>\\n      <td>Hawkins</td>\\n      <td>Denver</td>\\n      <td>M</td>\\n    </tr>\\n    <tr>\\n      <td>Judy</td>\\n      <td>Day</td>\\n      <td>Los Angeles</td>\\n      <td>F</td>\\n    </tr>\\n    <tr>\\n      <td>Ashley</td>\\n      <td>Ruiz</td>\\n      <td>San Francisco</td>\\n      <td>F</td>\\n    </tr>\\n    <tr>\\n      <td>Stephanie</td>\\n      <td>Gomez</td>\\n      <td>Portland</td>\\n      <td>F</td>\\n    </tr>\\n  </tbody>\\n</table>',\n",
       " 'languages': ['eng'],\n",
       " 'filetype': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n",
       " 'category': 'Table',\n",
       " 'element_id': '593be20183e1c54bb956653513942db0'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = docs[0].metadata['text_as_html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>First Name</td>\n",
      "      <td>Last Name</td>\n",
      "      <td>City</td>\n",
      "      <td>Gender</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Brandon</td>\n",
      "      <td>James</td>\n",
      "      <td>Miami</td>\n",
      "      <td>M</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Sean</td>\n",
      "      <td>Hawkins</td>\n",
      "      <td>Denver</td>\n",
      "      <td>M</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Judy</td>\n",
      "      <td>Day</td>\n",
      "      <td>Los Angeles</td>\n",
      "      <td>F</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Ashley</td>\n",
      "      <td>Ruiz</td>\n",
      "      <td>San Francisco</td>\n",
      "      <td>F</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Stephanie</td>\n",
      "      <td>Gomez</td>\n",
      "      <td>Portland</td>\n",
      "      <td>F</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>First Name</td>\n",
       "      <td>Last Name</td>\n",
       "      <td>City</td>\n",
       "      <td>Gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Brandon</td>\n",
       "      <td>James</td>\n",
       "      <td>Miami</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sean</td>\n",
       "      <td>Hawkins</td>\n",
       "      <td>Denver</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Judy</td>\n",
       "      <td>Day</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ashley</td>\n",
       "      <td>Ruiz</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gomez</td>\n",
       "      <td>Portland</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City | Gender |\n",
      "| --- | --- | --- | --- |\n",
      "| Brandon | James | Miami | M |\n",
      "| Sean | Hawkins | Denver | M |\n",
      "| Judy | Day | Los Angeles | F |\n",
      "| Ashley | Ruiz | San Francisco | F |\n",
      "| Stephanie | Gomez | Portland | F |\n"
     ]
    }
   ],
   "source": [
    "question = \"Return the Data in Markdown format.\"\n",
    "\n",
    "response = ask_llm(context=context,\n",
    "                   question=question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City    | Gender |\n",
      "|:-----------|:----------|:---------|:-------|\n",
      "| Judy       | Day        | Los Angeles| F       |\n",
      "| Ashley     | Ruiz       | San Francisco| F       |\n",
      "| Stephanie  | Gomez      | Portland   | F       |\n"
     ]
    }
   ],
   "source": [
    "question = \"Return all entris in the table where Gender is 'F'. Format the response in Markdown. Do not write preambles and explanation.\"\n",
    "\n",
    "response = ask_llm(context=context,\n",
    "                   question=question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City        | Gender |\n",
      "|:-----------|:----------|:------------|:-------|\n",
      "| Brandon    | James     | Miami       | M       |\n",
      "| Sean       | Hawkins   | Denver      | M       |\n"
     ]
    }
   ],
   "source": [
    "question = \"Return all entris in the table where Gender is 'male'. Format the response in Markdown. Do not write preambles and explanation.\"\n",
    "\n",
    "response = ask_llm(context=context,\n",
    "                   question=question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 3: Personalized Job Application Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import  Docx2txtLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Docx2txtLoader(\"data/job_description.docx\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/job_description.docx'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Description - Data Scientist\n",
      "\n",
      "At SpiceJet, we rely on data to provide us valuable insights, and to automate our systems and solutions to help us increase revenues, reduce costs and provide improved customer experiences. We are seeking an experienced data scientist to deliver insights and automate our systems and processes. Ideal team member will have mathematical and statistical expertise, experience with modern data science programming languages and machine learning/AI platforms and techniques. You will mine, clean and interpret our data and then develop machine learning models to deliver business value across different parts of the business. \n",
      "\n",
      "Objectives of this Role\n",
      "\n",
      "Use Data Science and Machine Learning to increase revenue, reduce costs and increase customer satisfaction.\n",
      "\n",
      "Collaborate with product design and engineering to develop an understanding of needs\n",
      "\n",
      "Understand where the required data resides and work on ways to extract the relevant data.\n",
      "\n",
      "Research and devise statistical and machine learning models.\n",
      "\n",
      "Communicate insights to stakeholders in an automated fashion to enable them to take business decisions.\n",
      "\n",
      "Deploy models in production to automate various processes.\n",
      "\n",
      "\n",
      "\n",
      "Skills and Qualifications\n",
      "\n",
      "Bachelor’s degree in Data Science, Computer Science, Statistics, Applied mathematics, or related discipline\n",
      "\n",
      "3+ years experience in data science\n",
      "\n",
      "Proficiency with Machine Learning platforms and techniques, data mining, mathematics, and statistical analysis\n",
      "\n",
      "Predictive modelling experience\n",
      "\n",
      "Experience with Python, R, Excel, Tableau, SQL\n",
      "\n",
      "Comfortable working in a dynamic, research-oriented group with several ongoing concurrent projects\n",
      "\n",
      "\n",
      "\n",
      "Preferred Qualifications\n",
      "\n",
      "Master’s degree in Data Science, Computer Science, Stats, Applied math, or related discipline\n",
      "\n",
      "2+ years of project management experience\n",
      "\n",
      "\n",
      "\n",
      "Competencies:\n",
      "\n",
      "Defining: Can translate fuzzy problem in assigned area into formalized structure\n",
      "\n",
      "Troubleshooting: Can troubleshoot unseen problems in assigned area\n",
      "\n",
      "Solutioning:  Can independently implement the solution\n",
      "\n",
      "Coding Principles: Extensability, Abstraction, Separation of concerns, Chooses right Data Science/Machine learning techniques.\n",
      "\n",
      "Coding Quality: Performant, Integration tests coverage, implements security requirements.\n",
      "\n",
      "Programming Language Proficiency: Usage of design patterns and knowledge of functional aspects.\n",
      "\n",
      "Project Management: Can break down tasks, identify dependencies and provide accurate effort estimates that feed into the larger plan. Proactively resolve dependencies and communicate around progress and blockers.\n",
      "\n",
      "Execution: Responsible for timely completion of assigned components including integration and deployment to appropriate environments. Complete ownership of quality including iterations with stakeholders to meet the desired objectives.\n",
      "\n",
      "Responsiveness: Understands team priorities. Own, identify and quick turn around for production issues that address the root cause.\n",
      "\n",
      "Designing: Low level design, functional modeling, Adaptability, High level design with guidance\n",
      "\n",
      "Analysis: Understanding impact of design changes\n",
      "\n",
      "Non Functional Attributes: Understands the basic concepts around performance and can contribute to measuring and improving performance. Understands scalability\n",
      "\n",
      "Data Orientation: Apply algorithms to make smarter and intelligent data driven systems, Good understanding and know hows of various data tools/tech (e.g. Data Tools, IR and ML tools)\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Data Scientist Position at SpiceJet\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am excited to apply for the Data Scientist position at SpiceJet. As a recent graduate from IIT with a focus on Natural Language Processing and Machine Learning, I am confident in my ability to deliver insights and automate systems using data science and machine learning techniques.\n",
      "\n",
      "With a solid foundation in mathematical and statistical expertise, experience with modern programming languages such as Python and R, and proficiency in machine learning platforms and techniques, I am well-equipped to drive business value across different parts of the organization. My strong understanding of NLP and ML concepts enables me to apply algorithms to make smarter and intelligent data-driven systems.\n",
      "\n",
      "I am eager to collaborate with product design and engineering teams to develop an understanding of needs and devise statistical and machine learning models that drive revenue growth, reduce costs, and enhance customer satisfaction. I look forward to discussing my application and how I can contribute to SpiceJet's success.\n",
      "\n",
      "Sincerely,\n",
      "Aaditya\n"
     ]
    }
   ],
   "source": [
    "question =\"\"\"\n",
    "My name is Aaditya, and I am a recent graduate from IIT with a focus on Natural Language Processing and Machine Learning.\n",
    "I am applying for a Data Scientist position at SpiceJet.\n",
    "Please write a concise job application email for me in short(about 100-150 words), removing any placeholders, including references to job boards or sources.\n",
    "\"\"\"\n",
    "\n",
    "response = ask_llm(context,question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krishgenai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
